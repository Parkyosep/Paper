{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNXpw0MluoLOGOYu/3fcoUq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UgnVO7lGRFdI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from typing import Any, Callable, List, Optional, Tuple\n",
        "from easydict import EasyDict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "yypD70Qj0k7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x:Tensor):\n",
        "        x = self.conv(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "MAdiwELzv04T"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_channels, n1x1, n3x3_reduce, n3x3, n5x5_reduce, n5x5, pool_proj):\n",
        "        super(Inception, self).__init__()\n",
        "        self.branch1 = ConvBlock(in_channels, n1x1, kernel_size = 1, stride = 1, padding = 0)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            ConvBlock(in_channels, n3x3_reduce, kernel_size = 1, stride = 1, padding = 0),\n",
        "            ConvBlock(n3x3_reduce, n3x3, kernel_size = 3, stride = 1, padding = 1)\n",
        "        )\n",
        "        \n",
        "        self.branch3 = nn.Sequential(\n",
        "            ConvBlock(in_channels, n5x5_reduce, kernel_size = 1, stride = 1, padding = 0),\n",
        "            ConvBlock(n5x5_reduce, n5x5, kernel_size = 5, stride = 1, padding = 2)\n",
        "        )\n",
        "        \n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),\n",
        "            ConvBlock(in_channels, pool_proj, kernel_size = 1, stride = 1, padding = 0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x:Tensor):\n",
        "        x1 = self.branch1(x)\n",
        "        x2 = self.branch2(x)\n",
        "        x3 = self.branch3(x)\n",
        "        x4 = self.branch4(x)\n",
        "\n",
        "        return torch.cat([x1, x2, x3, x4], dim = 1)"
      ],
      "metadata": {
        "id": "HRieQj8DynvO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionAux(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(InceptionAux, self).__init__()\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size = 5, stride = 3)\n",
        "        self.conv = ConvBlock(in_channels, 128, kernel_size = 1, stride = 1, padding = 0)\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "        self.dropout = nn.Dropout(p = 0.7)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x:Tensor):\n",
        "        x = self.avgpool(x)\n",
        "        x = self.conv(x)\n",
        "        # flatten\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "zlhn1PhwrnlU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self, aux_logits = True, num_classes = 1000):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        # if aux_logits not boolean, assert\n",
        "        assert aux_logits == True or aux_logits == False\n",
        "        self.aux_logits = aux_logits\n",
        "\n",
        "        # 224 x 224 x 3 -> 112 x 112 x 64, 7x7+2(S)\n",
        "        self.conv1 = ConvBlock(in_channels = 3, out_channels = 64, kernel_size = 7, stride = 2, padding = 3)\n",
        "        # maxpool with ceil, 3x3 + 2(S), 112 x 112 x 64 -> 56 x 56 x 64\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size = 3, stride = 2, ceil_mode = True)\n",
        "        # 56 x 56 x 64 -> 56 x 56 x 64, 3x3 reduce\n",
        "        self.conv2 = ConvBlock(in_channels = 64, out_channels = 64, kernel_size = 1, stride = 1, padding = 0)\n",
        "        # 56 x 56 x 64 -> 56 x 56 x 192\n",
        "        self.conv3 = ConvBlock(in_channels = 64, out_channels = 192, kernel_size = 3, stride = 1, padding = 1)\n",
        "        # 56 x 56 x 192 -> 28 x 28 x 192\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size = 3, stride = 2, ceil_mode = True)\n",
        "\n",
        "        # 28 x 28 x 192 -> 28 x 28 x 256\n",
        "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
        "        # 28 x 28 x 256 -> 28 x 28 x 480\n",
        "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
        "        # 28 x 28 x 480 -> 14 x 14 x 480\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size = 3, stride = 2, ceil_mode = True)\n",
        "\n",
        "        # 14 x 14 x 480 -> 14 x 14 x 512\n",
        "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
        "        # 14 x 14 x 512 -> 14 x 14 x 512\n",
        "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
        "        # 14 x 14 x 512 -> 14 x 14 x 512\n",
        "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
        "        # 14 x 14 x 512 -> 14 x 14 x 528\n",
        "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
        "        # 14 x 14 x 528 -> 14 x 14 x 832\n",
        "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
        "        # 14 x 14 x 832 -> 7 x 7 x 832\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size = 3, stride = 2, ceil_mode = True)\n",
        "\n",
        "        # 7 x 7 x 832 -> 7 x 7 x 832\n",
        "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
        "        # 7 x 7 x 832 -> 7 x 7 x 1024\n",
        "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        # 7 x 7 x 1024 -> 1 x 1 x 1024\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size = 7, stride = 1)\n",
        "        self.dropout = nn.Dropout(p = 0.4)\n",
        "        # 1024 -> 1000(num_classes)\n",
        "        self.linear = nn.Linear(1024, num_classes)\n",
        "\n",
        "\n",
        "        if self.aux_logits:\n",
        "            self.aux1 = InceptionAux(512, num_classes) # inception4a\n",
        "            self.aux2 = InceptionAux(528, num_classes) # inception4d\n",
        "\n",
        "        else:\n",
        "            self.aux1 = None\n",
        "            self.aux2 = None\n",
        "    \n",
        "    def forward(self, x:Tensor):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.maxpool2(x)\n",
        "        \n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "        \n",
        "        x = self.inception4a(x)\n",
        "        \n",
        "        if self.aux_logits and self.training:\n",
        "            aux1 = self.aux1(x)\n",
        "        else:\n",
        "            aux2 = None\n",
        "        \n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        \n",
        "        if self.aux_logits and self.training:\n",
        "            aux2 = self.aux2(x)\n",
        "        else:\n",
        "            aux2 = None\n",
        "\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "        x = self.avgpool(x)\n",
        "        # N x 1024 x 1 x 1 -> N x 1024\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = self.linear(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        if self.aux_logits and self.training:\n",
        "            return x, aux1, aux2\n",
        "        else:\n",
        "            return x"
      ],
      "metadata": {
        "id": "dtFSDRDL2ze9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    x = torch.randn(3, 3, 224, 224)\n",
        "    model = GoogLeNet(aux_logits = True, num_classes = 1000)\n",
        "    print(model(x)[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HjsAmUIwHwa",
        "outputId": "63c00e29-c389-49ac-e6b6-7a5290686d59"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train  \n",
        "Train model by CIFAR-10 datasets"
      ],
      "metadata": {
        "id": "ejv0jZr80nxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    # preprocess\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        transforms.Resize((224, 224))\n",
        "    ])\n",
        "\n",
        "    # load data\n",
        "    train = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
        "    test = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
        "    train_loader = DataLoader(train, batch_size=args.batch_size, shuffle = True)\n",
        "    test_loader = DataLoader(test, batch_size=args.batch_size, shuffle=True)\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "l1tXrhGezaPu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    args = EasyDict()\n",
        "    args.batch_size = 100\n",
        "    args.learning_rate = 0.0002\n",
        "    args.n_epochs = 100\n",
        "    args.plot = True\n",
        "\n",
        "    np.random.seed(1)\n",
        "    seed = torch.manual_seed(1)\n",
        "\n",
        "    # load dataset\n",
        "    train_loader, test_loader = load_dataset()\n",
        "\n",
        "    # model, loss, optimizer\n",
        "    losses = []\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"we use GPU\")\n",
        "    else:\n",
        "        print(\"we use CPU\")\n",
        "    model = GoogLeNet(aux_logits = True, num_classes = 10).to(device)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "    # train\n",
        "    for epoch in range(args.n_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct, count = 0,0\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader, start=1):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output, aux1, aux2 = model.forward(images)\n",
        "            loss_output = criterion(output, labels)\n",
        "            loss_aux1 = criterion(aux1, labels)\n",
        "            loss_aux2 = criterion(aux2, labels)\n",
        "            loss = loss_output + 0.3 * (loss_aux1 + loss_aux2)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, preds = torch.max(output, 1) # torch max output is max, max_index\n",
        "            count += labels.size(0)\n",
        "            correct += torch.sum(preds==labels)\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"[*] Epoch: {epoch} \\tStep: {batch_idx}/{len(train_loader)}\\tTrain accuracy: {correct/count} \\tTrain Loss: {(train_loss/count)*100}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C9fqyPSa2cFW",
        "outputId": "150759ae-802e-4769-f05c-aef92a9cc481"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "we use GPU\n",
            "[*] Epoch: 13 \tStep: 260/500\tTrain accuracy: 0.6883845925331116 \tTrain Loss: 0.7185489911299485\n",
            "[*] Epoch: 13 \tStep: 270/500\tTrain accuracy: 0.6874814629554749 \tTrain Loss: 0.7199741412092138\n",
            "[*] Epoch: 13 \tStep: 280/500\tTrain accuracy: 0.6872857213020325 \tTrain Loss: 0.7211960792541504\n",
            "[*] Epoch: 13 \tStep: 290/500\tTrain accuracy: 0.6872414350509644 \tTrain Loss: 0.7212720498956483\n",
            "[*] Epoch: 13 \tStep: 300/500\tTrain accuracy: 0.6869666576385498 \tTrain Loss: 0.7218428881963095\n",
            "[*] Epoch: 13 \tStep: 310/500\tTrain accuracy: 0.6867096424102783 \tTrain Loss: 0.7223478286497055\n",
            "[*] Epoch: 13 \tStep: 320/500\tTrain accuracy: 0.6864375472068787 \tTrain Loss: 0.7223972564563155\n",
            "[*] Epoch: 13 \tStep: 330/500\tTrain accuracy: 0.6858181953430176 \tTrain Loss: 0.7234349940762376\n",
            "[*] Epoch: 13 \tStep: 340/500\tTrain accuracy: 0.68644118309021 \tTrain Loss: 0.7232403337955474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    model.eval()\n",
        "    correct, count = 0,0\n",
        "    valid_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(test_loader, start=1):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            output = model.forward(images)\n",
        "            loss = criterion(output, labels)\n",
        "            valid_loss += loss.item()\n",
        "            _, preds = torch.max(output, 1)\n",
        "            count += labels.size(0)\n",
        "            correct += torch.sum(preds==labels)\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"[*] Step: {batch_idx}/{len(test_loader)}\\tValid accuracy: {correct/count} \\tValid Loss: {(valid_loss/count)*100}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQPWltZT-O4S",
        "outputId": "517ab83b-a054-4a42-95f8-fe1cd216e0cc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Step: 10/100\tValid accuracy: 0.8630000352859497 \tValid Loss: 0.45474811792373654\n",
            "[*] Step: 20/100\tValid accuracy: 0.862000048160553 \tValid Loss: 0.4923530235886574\n",
            "[*] Step: 30/100\tValid accuracy: 0.8659999966621399 \tValid Loss: 0.487832265595595\n",
            "[*] Step: 40/100\tValid accuracy: 0.8662500381469727 \tValid Loss: 0.4847776528447866\n",
            "[*] Step: 50/100\tValid accuracy: 0.8673999905586243 \tValid Loss: 0.48437747985124585\n",
            "[*] Step: 60/100\tValid accuracy: 0.8693333268165588 \tValid Loss: 0.47821816181143123\n",
            "[*] Step: 70/100\tValid accuracy: 0.8684285879135132 \tValid Loss: 0.4816110055361475\n",
            "[*] Step: 80/100\tValid accuracy: 0.8676250576972961 \tValid Loss: 0.4828685568645597\n",
            "[*] Step: 90/100\tValid accuracy: 0.8684444427490234 \tValid Loss: 0.48009414788749477\n",
            "[*] Step: 100/100\tValid accuracy: 0.8672999739646912 \tValid Loss: 0.4842480953037739\n"
          ]
        }
      ]
    }
  ]
}
